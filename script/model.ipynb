{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Random Forest regression model to data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, feature engineering and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date    datetime    dateweek  player_id  current_club_id  \\\n",
      "0     2022-08-05  2022-08-05  2022-08-01      41414              398   \n",
      "1     2022-08-05  2022-08-05  2022-08-01     661284            55686   \n",
      "2     2022-07-29  2022-07-29  2022-07-25     663225               29   \n",
      "3     2022-07-29  2022-07-29  2022-07-25     670883              148   \n",
      "4     2022-07-29  2022-07-29  2022-07-25     289846             1010   \n",
      "...          ...         ...         ...        ...              ...   \n",
      "2312  2021-12-22  2021-12-22  2021-12-20     377387              167   \n",
      "2313  2021-12-16  2021-12-16  2021-12-13      76277               40   \n",
      "2314  2021-10-13  2021-10-13  2021-10-11      26399              131   \n",
      "2315  2021-10-05  2021-10-05  2021-10-04     592474              987   \n",
      "2316  2021-10-05  2021-10-05  2021-10-04     627248               29   \n",
      "\n",
      "      market_value_in_eur player_club_domestic_competition_id  \\\n",
      "0                 1000000                                 IT1   \n",
      "1                  300000                                UKR1   \n",
      "2                  450000                                 GB1   \n",
      "3                 2000000                                 GB1   \n",
      "4                 1200000                                 GB1   \n",
      "...                   ...                                 ...   \n",
      "2312              1000000                                  L1   \n",
      "2313              3000000                                 FR1   \n",
      "2314             15000000                                 ES1   \n",
      "2315               200000                                 SC1   \n",
      "2316               300000                                 GB1   \n",
      "\n",
      "                   name  club_id              club_name  ...   Off   Crs  \\\n",
      "0           Lucas Leiva      398              Lazio Rom  ...  0.00  0.16   \n",
      "1               Fabinho    55686  Metalist 1925 Kharkiv  ...  0.00  0.23   \n",
      "2         Tyler Onyango       29             Fc Everton  ...  0.00  0.00   \n",
      "3         Dane Scarlett      148      Tottenham Hotspur  ...  0.00  0.00   \n",
      "4       Ashley Fletcher     1010             Fc Watford  ...  0.00  0.00   \n",
      "...                 ...      ...                    ...  ...   ...   ...   \n",
      "2312     Sergio Córdova      167            Fc Augsburg  ...  1.39  0.83   \n",
      "2313  Laurent Koscielny       40  Fc Girondins Bordeaux  ...  0.00  0.00   \n",
      "2314      Sergio Agüero      131           Fc Barcelona  ...  0.59  2.35   \n",
      "2315   Stuart McKinstry      987          Motherwell Fc  ...  0.00  0.00   \n",
      "2316       Lewis Dobbin       29             Fc Everton  ...  0.00  2.50   \n",
      "\n",
      "      TklW PKwon PKcon   OG  Recov  AerWon  AerLost  AerWon%  \n",
      "0     1.85   0.0   0.0  0.0  10.20    1.53     1.06     59.2  \n",
      "1     1.44   0.0   0.0  0.0  12.10    1.75     1.09     61.6  \n",
      "2     0.00   0.0   0.0  0.0   3.33    3.33     3.33     50.0  \n",
      "3     0.00   0.0   0.0  0.0   0.00    0.00     0.00      0.0  \n",
      "4     6.67   0.0   0.0  0.0  13.30    6.67    20.00     25.0  \n",
      "...    ...   ...   ...  ...    ...     ...      ...      ...  \n",
      "2312  1.11   0.0   0.0  0.0   5.56    5.56     5.56     50.0  \n",
      "2313  0.77   0.0   0.1  0.0   7.88    1.63     0.67     70.8  \n",
      "2314  0.59   0.0   0.0  0.0   1.76    2.35     1.18     66.7  \n",
      "2315  0.00   0.0   0.0  0.0   2.00    0.00     0.00      0.0  \n",
      "2316  5.00   0.0   0.0  0.0   5.00    0.00    15.00      0.0  \n",
      "\n",
      "[2317 rows x 154 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/merged_data.csv\")\n",
    "positions = [(data.Pos == \"FW\") | (data.Pos == \"FWMF\") | (data.Pos == \"FWDF\"),\n",
    "             (data.Pos == \"MF\") | (data.Pos == \"MFFW\") | (data.Pos == \"MFDF\"),\n",
    "             (data.Pos == \"DF\") | (data.Pos == \"DFMF\") | (data.Pos == \"DFFW\")]\n",
    "posNames = [\"Forward\",\"Midfielder\",\"Defender\"]\n",
    "gPos = np.select(positions,posNames)\n",
    "\n",
    "# Create encoding for the categorical variable\n",
    "new_var = pd.get_dummies(gPos, drop_first=True)\n",
    "print(data)\n",
    "\n",
    "data_new = data.join(new_var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test train split and transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new.drop(columns=[\"market_value_in_eur\"]).select_dtypes(exclude=['object'])\n",
    "Y = data_new['market_value_in_eur']\n",
    "\n",
    "Y_log = np.log(Y)\n",
    "X_scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled,Y_log,test_size = 0.33, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vars</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP</td>\n",
       "      <td>666.554232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90s</td>\n",
       "      <td>646.151480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Min</td>\n",
       "      <td>646.054621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Starts</td>\n",
       "      <td>627.899742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stadium_seats</td>\n",
       "      <td>192.941653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DriSucc%</td>\n",
       "      <td>167.013145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PasLonCmp%</td>\n",
       "      <td>135.312114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ShoDist</td>\n",
       "      <td>132.188172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G/SoT</td>\n",
       "      <td>125.037578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SoT%</td>\n",
       "      <td>116.064710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rec</td>\n",
       "      <td>108.113665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carries</td>\n",
       "      <td>103.568894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RecTarg</td>\n",
       "      <td>102.331832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CarTotDist</td>\n",
       "      <td>93.006777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PasGround</td>\n",
       "      <td>91.762046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CarProg</td>\n",
       "      <td>81.926126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CarPrgDist</td>\n",
       "      <td>80.203982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PasTotCmp%</td>\n",
       "      <td>78.620781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PasShoCmp</td>\n",
       "      <td>77.825126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G/Sh</td>\n",
       "      <td>69.733176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             vars      scores\n",
       "0              MP  666.554232\n",
       "1             90s  646.151480\n",
       "2             Min  646.054621\n",
       "3          Starts  627.899742\n",
       "4   stadium_seats  192.941653\n",
       "5        DriSucc%  167.013145\n",
       "6      PasLonCmp%  135.312114\n",
       "7         ShoDist  132.188172\n",
       "8           G/SoT  125.037578\n",
       "9            SoT%  116.064710\n",
       "10            Rec  108.113665\n",
       "11        Carries  103.568894\n",
       "12        RecTarg  102.331832\n",
       "13     CarTotDist   93.006777\n",
       "14      PasGround   91.762046\n",
       "15        CarProg   81.926126\n",
       "16     CarPrgDist   80.203982\n",
       "17     PasTotCmp%   78.620781\n",
       "18      PasShoCmp   77.825126\n",
       "19           G/Sh   69.733176"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = SelectKBest(score_func = f_regression, k = 20)\n",
    "fs.fit(X_train, Y_train)\n",
    "\n",
    "X_train_red = fs.transform(X_train)\n",
    "X_test_red = fs.transform(X_test)\n",
    "\n",
    "vars = pd.DataFrame(X.columns, columns = ['vars'])\n",
    "scores = pd.DataFrame(fs.scores_, columns = ['scores'])\n",
    "\n",
    "vars.join(scores).sort_values(by = 'scores', ascending=False).head(20).reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the regression framework (f_regression), these are the 20 variables that perform the best. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training data is: 0.4676995953678198\n",
      "R^2 for testing data is: 0.4763105575048827\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "regr.fit(X_train_red, Y_train)\n",
    "print(\"R^2 for training data is:\", regr.score(X_train_red, Y_train))\n",
    "print(\"R^2 for testing data is:\", regr.score(X_test_red, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the regression show clear signs of overfitting, we need to apply regularization. Ridge regression is also referred to as L2 Regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training data is 0.46732165011547966\n",
      "R^2 for testing data is 0.47525845439570746\n",
      "Alpha used is 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:1791: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  w = ((singvals_sq + alpha) ** -1) - (alpha ** -1)\n"
     ]
    }
   ],
   "source": [
    "#linear_model.Ridge(alpha = 0.1, random_state = 0).fit(X_train_red, Y_train)\n",
    "regr = linear_model.RidgeCV(alphas = [0.01, 0.1, 1, 10]).fit(X_train_red, Y_train) # Does the hyper parameter tuning for us\n",
    "\n",
    "print(\"R^2 for training data is {}\".format(regr.score(X_train_red, Y_train)))\n",
    "print(\"R^2 for testing data is {}\".format(regr.score(X_test_red, Y_test)))\n",
    "print(\"Alpha used is {}\".format(regr.alpha_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model with depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training data is: 0.4073640699900307\n",
      "R^2 for testing data is: 0.38086821198679177\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0).fit(X_train_red, Y_train)\n",
    "\n",
    "print(\"R^2 for training data is:\", regr.score(X_train_red, Y_train))\n",
    "print(\"R^2 for testing data is:\", regr.score(X_test_red, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters was: RandomForestRegressor(max_depth=5, random_state=0)\n",
      "Best score was: 0.46742572961517004\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=RandomForestRegressor(random_state=0), param_grid = param_grid, cv = 5)\n",
    "search.fit(X_train_red, Y_train)\n",
    "print(\"Best parameters was: {}\".format(search.best_estimator_))\n",
    "print(\"Best score was: {}\".format(search.best_score_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training data is: 0.7097531363692727\n",
      "R^2 for testing data is: 0.5195733303251673\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor(random_state=0)\n",
    "regr.fit(X_train_red, Y_train)\n",
    "\n",
    "print(\"R^2 for training data is:\", regr.score(X_train_red, Y_train))\n",
    "print(\"R^2 for testing data is:\", regr.score(X_test_red, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters was: GradientBoostingRegressor(learning_rate=0.01, max_depth=5, min_samples_split=5,\n",
      "                          random_state=0)\n",
      "Best score was: 0.4030636842159071\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [2,3,4,5],\n",
    "    \"min_samples_split\": [2,3,4,5],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"loss\": [\"squared_error\"],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=GradientBoostingRegressor(random_state=0), param_grid = param_grid, cv = 5)\n",
    "search.fit(X_train_red, Y_train)\n",
    "print(\"Best parameters was: {}\".format(search.best_estimator_))\n",
    "print(\"Best score was: {}\".format(search.best_score_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost shows signs of overfitting, and may therefore not be the best choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for training data is: 0.7928114889734811\n",
      "R^2 for testing data is: 0.35820431489201765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regr = MLPRegressor(random_state=0, activation='logistic', solver = 'lbfgs', alpha = 1, max_iter = 1000).fit(X_train_red, Y_train)\n",
    "print(\"R^2 for training data is:\", regr.score(X_train_red, Y_train))\n",
    "print(\"R^2 for testing data is:\", regr.score(X_test_red, Y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters was: MLPRegressor(activation='logistic', alpha=1, max_iter=2000, random_state=0,\n",
      "             solver='lbfgs')\n",
      "Best score was: 0.31101179992994804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'activation': ['logistic'], \n",
    "    'solver': ['lbfgs'], \n",
    "    'alpha': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=MLPRegressor(random_state=0, max_iter = 2000), param_grid = param_grid, cv = 5)\n",
    "search.fit(X_train_red, Y_train)\n",
    "print(\"Best parameters was: {}\".format(search.best_estimator_))\n",
    "print(\"Best score was: {}\".format(search.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
